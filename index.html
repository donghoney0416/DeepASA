<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="600"/>
  <meta property="og:image:height" content="315"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DeepASA</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DeepASA: An Object-Oriented One-for-All Network for Auditory Scene Analysis</h1>
            <div class="is-size-4 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a>Anonymous Author(s)</a>
                  </div>

                  <div class="is-size-4 publication-authors">
                    <span class="author-block">Affiliation<br>NeurIPS 2025</span>
                    <span class="eql-cntrb"></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://donghoney0416.github.io/DeepASA/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
  
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://donghoney0416.github.io/DeepASA/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- BibTeX link -->
                  <span class="link-block">
                    <a href="https://donghoney0416.github.io/DeepASA/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-book"></i>
                    </span>
                    <span>BibTeX</span>
                  </a>
                </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://donghoney0416.github.io/DeepASA/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Demo-video -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-quarter">
        <h2 class="title is-2">Real-world Demo Video</h2>
        <div style="display: flex; justify-content: center; align-items: center;">
          <video controls width="1080">
            <source src="static/videos/demo_video_accepted.mp4" type="video/mp4">
            Your browser does not support the video tag. Please download the video
            <a href="static/videos/demo_video_accepted.mp4">here</a>.
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End demo video -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/19/plot.png" alt="MY ALT TEXT" width="640"/>
        <h2 class="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 4)
        </h2>
        <!-- Your audio here -->
        <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
          <div style="text-align: center;">
            <p style="color: black;"><strong>Mixed</strong></p>
            <audio controls style="width: 200px;">
              <source src="static/examples/19/19_mix.wav" type="audio/wav">
            </audio>
          </div>
          <div style="text-align: center;">
            <p style="color: black;"><strong>GT Source 1</strong></p>
            <audio controls style="width: 300px;">
              <source src="static/examples/19/19_spk1.wav" type="audio/wav">
            </audio>
          </div>
          <div style="text-align: center;">
            <p style="color: black;"><strong>Est Source 1</strong></p>
            <audio controls style="width: 300px;">
              <source src="static/examples/19/19_spk1_p.wav" type="audio/wav">
            </audio>
          </div>
        </div>

      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/19/plot.png" alt="MY ALT TEXT" width="640"/>
        <="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 4)
        </h2>
      </div>
      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/15/plot.png" alt="MY ALT TEXT" width="640"/>
        <h2 class="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 5)
        </h2>
      </div>
      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/12/plot.png" alt="MY ALT TEXT" width="640"/>
        <h2 class="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 4)
        </h2>
      </div>
      <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/10/plot.png" alt="MY ALT TEXT" width="640"/>
        <h2 class="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 3)
        </h2>
      </div>
     <div class="item" style="text-align: center;">
        <!-- Your image here -->
        <img src="static/examples/3/plot.png" alt="MY ALT TEXT" width="640"/>
        <h2 class="subtitle has-text-centered">
          ASA result of our DeepASA on the ASA2 dataset. (number of sources: 2)
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-quarter">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified" style="font-size: 1.2rem" >
          <p>
            We propose <b>DeepASA</b>, a <b>one-for-all model for auditory scene analysis</b> that performs multichannel-to-multichannel (M2M) source separation, dereverberation, sound event detection (SED), audio classification, and direction-of-arrival (DoA) estimation within a unified framework. DeepASA is designed for complex auditory scenes where multiple, often similar, sound sources overlap in time and move dynamically in space. To achieve robust and consistent inference across tasks, we introduce an <font color="#e0754f"><b>object-oriented processing (OOP)</b></font> strategy. This approach encapsulates diverse auditory features into object-centric representations and refines them through a <font color="#497c27"><b>chain-of-inference (CoI)</b></font> mechanism. The pipeline comprises a dynamic temporal kernel-based feature extractor, a transformer-based aggregator, and an object separator that yields per-object features. These features feed into multiple task-specific decoders. Our object-centric formulation naturally resolves the parameter association ambiguity inherent in traditional track-wise processing. However, early-stage object separation can lead to failure in downstream ASA tasks. To address this, we implement temporal coherence matching (TCM) within the chain-of-inference, enabling multi-task fusion and iterative refinement of object features using estimated audio parameters. We evaluate DeepASA on representative spatial audio benchmark datasets, including ASA, MC-FUSS, and STARSS23. Experimental results show that our model achieves state-of-the-art performance across all evaluated tasks, demonstrating its effectiveness in both source separation and auditory parameter estimation under diverse spatial auditory scenes.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<!-- Single image with description and fixed width -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Centered Title -->
      <div class="has-text-centered">
        <h2 class="title is-2">Overview</h2>
      </div>
      <br>
      <figure class="image" style="margin: 0 auto; max-width: 960px;">
        <img src="static/images/DeepASA.png" alt="Result Image" style="width: 100%; height: auto;">
      </figure>

      <h3 class="subtitle is-5 mt-4" >
        <p>
          <strong>Overview of the DeepASA Framework for Auditory Scene Analysis (ASA)</strong> </br>
        </p>
      </h3>
    </div>
  </div>
</section>

<!-- Single image with description and fixed width -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Centered Title -->
      <div class="has-text-centered">
        <h2 class="title is-2">Object-oriented processing</h2>
      </div>
      <br>
      <figure class="image" style="margin: 0 auto; max-width: 1280px;">
        <img src="static/images/oop.png" alt="Result Image" style="width: 100%; height: auto;">
      </figure>
      <h3 class="subtitle is-5 mt-4">
          <strong>Illustration of the (a) traditional track-wise processing, and (b) proposed <font color="#497c27">object-oriented processing (OOP) </font>.</strong>
      </h3>
    </div>
  </div>
</section>

<!-- Single image with description and fixed width -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Centered Title -->
      <div class="has-text-centered">
        <h2 class="title is-2">Chain-of-Inference</h2>
      </div>
      <br>
      <figure class="image" style="margin: 0 auto; max-width: 960px;">
        <img src="static/images/CoI.png" alt="Result Image" style="width: 100%; height: auto;">
      </figure>
      <h3 class="subtitle is-5 mt-4">
          <strong>Illustration of the proposed <font color="#f5a100">chain-of-inference (CoI)</font>.</strong>
      </h3>
    </div>
  </div>
</section>


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h2 class="title is-2">Comparison with SOTA model on various datasets</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/asa2_sota.PNG" alt="MY ALT TEXT" width="640"/>
        </div>
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/mc_fuss_sota.PNG" alt="MY ALT TEXT" width="640"/>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/starss23_sota.PNG" alt="MY ALT TEXT" width="640"/>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<!--
  <section class="section" id="Citation">
    <div class="container is-max-desktop content">
      <h2 class="title">Citation</h2>
      <pre><code>
        @article{hong2025ita,
        title={ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On},
        author={Hong, Ji Woo and Ton, Tri and Pham, Trung X and Koo, Gwanhyeong and Yoon, Sunjae and Yoo, Chang D},
        journal={arXiv preprint arXiv:2503.20418},
        year={2025}}
    </code></pre>
    </div>
</section>

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>This work was supported by Institute for Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) (No.RS-2021-II211381, Development of Causal AI through Video Understanding and Reinforcement Learning, and Its Applications to Real Environments) and partly supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) (No.RS-2022-II220184, Development and Study of AI Technologies to Inexpensively Conform to Evolving Policy on Ethics)</p>
  </div>
</section>
-->

  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
